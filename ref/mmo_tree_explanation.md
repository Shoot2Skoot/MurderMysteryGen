Below is a â€œmetaâ€‘templateâ€ you can hand an LLM so it immediatelyâ€¯graspsâ€¯what an MMO (Motiveâ€¯â€“â€¯Meansâ€¯â€“â€¯Opportunity) mystery tree is and can author its own without mistaking the shape of the data.

1â€¯Â What the LLM must model
Level	Purpose	Cardinality	Typical content
Suspect	topâ€‘level container	â€¯â‰¥â€¯2	name, short bio
Branch	exactly three per suspect	Motive, Means, Opportunity	
Step (reason node)	0â€¯â€“â€¯N per branch (may branch further)	deductions, inferences, partial conclusions	
Evidence leaf	â‰¥â€¯1 per branch, may be shared across suspects/branches	physical objects, documents, witness notes	

Edges are directional (â€œsupports / leadsâ€‘toâ€).
Graph is acyclic but has convergence (shared leaves).

2â€¯Â Canonical JSON schema
jsonc
Copy code
{
  "suspects": [
    {
      "name": "Bob",
      "bio": "Timâ€™s college roommate, now accountant.",
      "branches": {
        "motive":   { "root": "Tim blackmailed Bob",        "steps": [ â€¦ ], "evidence": [ â€¦ ] },
        "means":    { "root": "Bob held the pyramid",       "steps": [ â€¦ ], "evidence": [ â€¦ ] },
        "opportunity": { "root": "Bob alone at sunset",     "steps": [ â€¦ ], "evidence": [ â€¦ ] }
      }
    }
    // â€¦ other suspects
  ],
  "evidence": [
    { "id": "EV_Brochure", "label": "House Brochure", "shared_by": ["Bob", "Amber", "Phoenix"] },
    { "id": "EV_Torn",     "label": "Torn Novel Page", "shared_by": ["Bob","Amber"] }
    // every leaf is declared once here
  ]
}
steps is an ordered list; if a step branches, embed a substeps list inside it.

Leaves reference evidence.id so one clue can appear in many places.

ğŸ”â€¯Why this shape?
Flat suspect listÂ â†’ easy sampling; exactlyâ€‘three branchesÂ â†’ enforces MMO; separating the global evidence array makes reuse explicit.

3â€¯Â Algorithmic rules the LLM should follow
For each suspect generate three root claims: 1â€¯Ã—â€¯Motive, 1â€¯Ã—â€¯Means, 1â€¯Ã—â€¯Opportunity.

Depth: 1â€“3 reasoning steps under each root.

Evidence: attach â‰¥â€¯1 leaves to every last step. 25â€“40â€¯% of evidence items should be reused in â‰¥â€¯2 branches (models â€œinterwovenâ€ feel).

Culprit logic (optional): exactly one suspectâ€™s MMO trio is fully corroborated & contradictionâ€‘free. Others break at â‰¥â€¯1 branch via missing or conflicting evidence.

No circular edges; a leaf never points back upward.

Hand those five bullet rules to the model right after the schema and it will know how to expand the tree.

4â€¯Â Tiny worked example (one suspect only)
json
Copy code
{
  "suspects":[
    {
      "name":"Amber",
      "branches":{
        "motive":{
          "root":"Tim threatened to expose birthâ€‘defect coverâ€‘up",
          "steps":[
            {
              "text":"Decoded note mentions reporter inquiry",
              "evidence":["EV_AmberMsg","EV_Brochure"]
            },
            {
              "text":"Toxic vitaminâ€‘A bottle proves negligence",
              "evidence":["EV_Bottle","EV_Pamphlet"]
            }
          ]
        },
        "means":{
          "root":"Amber never near murder weapon",
          "steps":[
            { "text":"Spa wing far from Mineral Room", "evidence":["EV_Map"] }
          ]
        },
        "opportunity":{
          "root":"Amber stuck in Yoga Studio at sunset",
          "steps":[
            { "text":"Participant log P4 shows her in Sauna", "evidence":["EV_Log"] }
          ]
        }
      }
    }
  ],
  "evidence":[
    {"id":"EV_AmberMsg","label":"Timâ†’Amber message"},
    {"id":"EV_Brochure","label":"House Brochure"},
    {"id":"EV_Bottle","label":"Supplement bottle 1800â€¯Âµg A"},
    {"id":"EV_Pamphlet","label":"Morpho pamphlet 700â€¯Âµg limit"},
    {"id":"EV_Map","label":"Wing map"},
    {"id":"EV_Log","label":"Participant logbook"}
  ]
}
Feed the example + rules â†’ ask â€œGenerate a complete 4â€‘suspect MMO graph in the same format.â€
The model now has:

the ontology (Suspectâ€¯â†’â€¯Branchâ€¯â†’â€¯Stepâ€¯â†’â€¯Evidence),

numeric constraints (3 branches, depth limits, reuse quota),

and a concrete instance to imitate.

5â€¯Â Prompt stub you can reuse
System: You are a mysteryâ€‘graph generator. Obey the schema below.
User: â€œCreate a new 5â€‘suspect MMO mystery. Follow:
â€‘ exactly 3 branches per suspect (motive/means/opportunity)
â€‘ 1â€“3 steps per branch
â€‘ each step ends in evidence ids
â€‘ 30â€¯% of evidence reused at least twice
â€‘ one suspectâ€™s evidence fully corroborates all three branches; for others at least one branch must lack or contradict evidence.â€

Append the JSON schema + mini example.
The LLM will now output a correctlyâ€‘structured mystery graph every time.

Why this solves the â€œLLMs donâ€™t get the structureâ€ problem
Schema forces hierarchy â€“ the model canâ€™t confuse levels.

Global evidence array + evidence[] references naturally produces shared leaves.

Numeric constraints in the prompt keep depth/width aligned with your design goals.

Sample instance anchors style, naming, and field order.

Once the model masters this representation, you can postâ€‘process it into Mermaid, Neo4j, game data, etc., confident it stayed inside the MMO framework.